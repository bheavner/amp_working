ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
testNames <- ensemblToGeneId(geneIds, ensembl)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = geneIds, ensembl)
geneNames[1]
geneNames$external_gene_name[1]
geneIds[1]
geneIds$V1[1]
as.character(geneIds$V1[1])
geneNames$ensembl_gene_id[1]
geneNames
geneNames$external_gene_name[1]
testNames[1]
testNames$external_gene_name[1]
geneNames[(order(match(geneNames$ensembl_gene_id, geneIds)))]
geneNames[(order(match(geneNames$ensembl_gene_id, geneIds))),]
geneNames <- geneNames[(order(match(geneNames$ensembl_gene_id, geneIds)))]
geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
geneNames <- geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
unique(geneIds)
setdif(geneIds, geneNames$ensembl_gene_id)
geneIds &in& geneNames$ensembl_gene_id
geneIds %in% geneNames$ensembl_gene_id
geneIds %in% geneNames$ensembl_gene_id[,]
geneIds %in% geneNames$ensembl_gene_id
setdiff(geneIds, geneNames$ensembl_gene_id)
setdiff(geneIds, as.list(geneNames$ensembl_gene_id))
geneNames$ensembl_gene_id
?setdiff
?setdiff
as.vector(geneNames$ensembl_gene_id)
setdiff(geneIds, as.vector(geneNames$ensembl_gene_id))
setdiff(as.vector(geneIds), as.vector(geneNames$ensembl_gene_id))
class(geneIds)
class(geneName)
geneIds
setdiff(as.vector(geneIds$V1), as.vector(geneNames$ensembl_gene_id))
geneIds
geneIds == "ENSMUSG00000019769"
geneNames[1]
geneNames$V1[1]
geneNames$ensembl_gene_id[1]
geneIds[1]
geneIds$V1[1]
geneNames$ensembl_gene_id[1]
require(biomaRt)
geneIds <- read.table("testIds.txt")
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
# use function to get gene name by ensembl_gene_id
testNames <- ensemblToGeneId(geneIds, ensembl)
# or grab them directly without the function
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = geneIds, ensembl)
geneIds[1]
geneIds$V1[1]
geneNames$ensembl_gene_id[1]
testNames[1]
testNames$external_gene_name[1]
as.character(geneIds$V1[1]) # ENSMUSG00000061808
geneIds$V1[1]
geneNames$ensembl_gene_id[1] # ENSMUSG00000001025
geneNames$external_gene_name[1] # "S100a6"
testNames$external_gene_name[1] # "S100a6" -- NOT WHAT I'D EXPECT WHEN CALLING FUNCTION
geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
match(geneNames$ensembl_gene_id, geneIds)
order(match(geneNames$ensembl_gene_id, geneIds)
)
match(geneNames$ensembl_gene_id, geneIds)
?match
match(as.vector(geneNames$ensembl_gene_id), geneIds)
match(as.vector(geneNames$ensembl_gene_id), as.vector(geneIds))
as.vector(geneIds)
geneNames$ensembl_gene_id
match(geneNames$ensembl_gene_id, geneIds)
match(geneIds, geneNames$ensembl_gene_id)
q()
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("https://github.com/PriceLab/AMP-ad/tree/0.2/MBB/TCX/normalize_readcounts.R")
# The files to normalize are:
# AMP-AD_MSBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts.txt.gz ('syn3667936')
# AMP-AD_MSBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_TranscriptCounts.txt.gz ('syn3667937')
countFileSynapseIDs <- c('syn3667936', 'syn3667937')
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE, check.names = FALSE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# If you get "error: Error in quantile.default(x, p = p) :
# missing values and NaN's not allowed if 'na.rm' is FALSE"
# expr$samples$lib.size shows a library size of 0 for problematic samples
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
# need to fix this naming
newFileName <- sub('_id_counts.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "Counts_normalized.txt", sep="")
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
q()
q()
path <- "/Users/bheavner/Desktop/AMP-AD_SampleSwap_UFL-Mayo-ISB_IlluminaHiSeq2000_dIPFC_Rush-Broad-SS_geneCounts_normalized.txt"
transcriptCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(transcriptCounts)
setwd("~/Projects/UO1-AMP/working/pilot_corrections")
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_Alzheimer_gene_id_counts.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(geneCounts)
library(gdata) # to read .xlsx file -  install.packages("gdata")
keyPath  <- "/Users/bheavner/Desktop/Data\ errors/ToSend/AD_MA_040915_IDsKey.xlsx"
keyHash <- read.xls(keyPath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
keyHash$IlluminaSampleID[match(colnames(geneCounts), keyHash$Path_ID)]
colnames(geneCounts) <- keyHash$IlluminaSampleID[match(colnames(geneCounts), keyHash$Path_ID)]
write.table(geneCounts, genePath) #, quote = FALSE, sep = " ", row.names = TRUE)
write.table(geneCounts, genePath) #, quote = FALSE, sep = " ", row.names = TRUE)
write.table(geneCounts, path) #, quote = FALSE, sep = " ", row.names = TRUE)
system(paste("gzip", genePath))
system(paste("gzip", path))
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_Alzheimer_TranscriptCounts_UpdatedID.txt"
transcriptCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(transcriptCounts)
keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
colnames(transcriptCounts) <- keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
write.table(transcriptCounts, path, quote = FALSE, sep = " ", row.names = TRUE)
test <- read.table(path, header = TRUE)
colnames(test)
test <- read.table(path, header = TRUE, check.names = FALSE)
colnames(test)
system(paste("gzip", path))
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("https://github.com/PriceLab/AMP-ad/pilotCorrections/normalize_readcounts.R")
countFileSynapseIDs <- c('syn3848699', 'syn38489268')
mergedCountFile = 'syn3848699'
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE, check.names = FALSE)
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
normFactors <- calcNormFactors(expr, method = ("TMM"))
normalizedCpm <- cpm(normFactors)
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
mergedCountFile  <- 'syn38489268'
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE, check.names = FALSE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
normalizedCpm <- cpm(normFactors)
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
mergedCountFile  <- 'syn3848926'
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE, check.names = FALSE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
normalizedCpm <- cpm(normFactors)
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_GeneCounts_UpdatedID.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(geneCounts)
sub('"', '', colnames(geneCounts)
)
?sub
sub('[\"]', '', colnames(geneCounts))
sub('[\\"]', '', colnames(geneCounts))
noquote(colnames(geneCounts))
write.table(geneCounts, path, quote = FALSE, sep = " ", row.names = TRUE, col.names = NA)
test <- read.table(path, header = TRUE, check.names = FALSE)
colnames(test)
?read.table
test <- read.table(path, header = TRUE, check.names = FALSE, quote = " ")
colnames(test)
colnames(test) = noquote(colnames(test))
colnames(test)
noquote(colnames(test))
system(paste("gzip", path, sep = " "))
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_GeneCounts_UpdatedID.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_GeneCounts_Normalized_UpdatedID.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(geneCounts)
sub('X', '', colnames(geneCounts))
colnames(geneCounts)  <- sub('X', '', colnames(geneCounts))
write.table(format(geneCounts, scientific = FALSE, digits = 5),
path, quote = FALSE, sep = "\t", row.names = TRUE, col.names = NA)
test <- read.table(path, header = TRUE, check.names = FALSE, quote = " ")
View(geneCounts)
View(geneCounts)
geneCounts[6,]
write.table(format(geneCounts, scientific = FALSE, digits = 5),
path, quote = FALSE, sep = "\t", row.names = TRUE, col.names = NA)
path
test <- read.table(path, header = TRUE, check.names = FALSE)
colnames(test)
system(paste("gzip", path, sep = " "))
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_Transcript_Counts_UpdatedID.txt"
transcriptCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(transcriptCounts)
keyPath  <- "/Users/bheavner/Desktop/Data\ errors/ToSend/PSP_MA_040915_IDsKey.xlsx"
keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
keyHash <- read.xls(keyPath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
colnames(transcriptCounts) <- keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
write.table(format(transcriptCounts, scientific = FALSE, digits = 5),
path, quote = FALSE, sep = "\t", row.names = TRUE, col.names = NA)
test <- read.table(path, header = TRUE, check.names = FALSE)
colnames(test)
write.table(transcriptCounts, path, quote = FALSE, sep = " ", row.names = TRUE, col.names = NA)
system(paste("gzip", path, sep = " "))
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_TranscriptCounts_Normalized_UpdatedID"
transcriptCounts <- read.table(path, header = TRUE, check.names = FALSE)
path <- "/Users/bheavner/Desktop/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_TranscriptCounts_Normalized_UpdatedID.txt"
transcriptCounts <- read.table(path, header = TRUE, check.names = FALSE)
keyPath  <- "/Users/bheavner/Desktop/Data\ errors/ToSend/PSP_MA_040915_IDsKey.xlsx"
keyHash <- read.xls(keyPath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
library(gdata) # to read .xlsx file -  install.packages("gdata")
keyHash <- read.xls(keyPath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
colnames(transcriptCounts)
keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
keyHash$Path_ID
colnames(transcriptCounts)  <- sub('X', '', colnames(transcriptCounts))
colnames(transcriptCounts)  <- sub('[.:punct:]', '-', colnames(transcriptCounts))
keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
colnames(transcriptCounts) <- keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
colnames(transcriptCounts)
write.table(format(transcriptCounts, scientific = FALSE, digits = 5),
path, quote = FALSE, sep = "\t", row.names = TRUE, col.names = NA)
test <- read.table(path, header = TRUE, check.names = FALSE)
colnames(test)
colnames(test)
system(paste("gzip", path, sep = " "))
library(synapseClient) # for synapse data exchange
library(tools) # for file path changes
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
synID <- "syn3483880"
# get info about current synapse object to modify
covariatesObject <- synGet(synID, downloadFile=F)
# define annotations as a list
covariatesObjectAnnotations <- list(consortium = "AMP-AD",
study = "TAUAPPms",
center = "UFL-Mayo-ISB",
dataType = "Covariates",
disease = "Alzheimers Disease",
platform = "IlluminaHiSeq2000",
mouseModel = "APP",
tissueTypeAbrv = "FB",
tissueType = "Forebrain",
fileType = "csv",
organism = "Mus musculus",
dataContact = "Ben Heavner ben.heavner@systemsbiology.org")
synSetAnnotations(covariatesObject) <- covariatesObjectAnnotations
# define activity
codeFile <- ("https://github.com/PriceLab/AMP-ad/blob/v0.2/UFL/APP/makeAPPCovariates.R")
act <- Activity(name='Covariate file generation',
executed = as.list(codeFile))
generatedBy(covariatesObject) = act
covariatesObject <- synStore(covariatesObject, forceVersion = T)
setwd("~/Projects/UO1-AMP/working/tau_corrections")
path <- "/Users/bheavner/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Updated.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(geneCounts)
sub('_', '.', colnames(geneCounts))
sub('P_', 'P', colnames(geneCounts))
colnames(geneCounts)<- sub('P_', 'P', colnames(geneCounts))
sub('_', '.', colnames(geneCounts))
colnames(geneCounts) <- sub('_', '.', colnames(geneCounts))
colnames(geneCounts)
write.table(geneCounts, path, quote = FALSE, sep = " ", row.names = TRUE, col.names = NA)
system(paste("gzip", path, sep = " "))
countFileSynapseIDs <- c('syn3910122') #'syn3772907',
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("https://github.com/TODO")
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(Counts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name) #legacy?
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(normalizedCpm, newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE, check.names = FALSE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(Counts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name) #legacy?
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(normalizedCpm, newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
file = 'AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Updated.txt.gz_normalized.txt'
test = read.table(file, header = TRUE, check.names = FALSE)
colnames(test)
gzip(file)
path <- "/Users/bheavner/Desktop/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Normalized_Updated.txt.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
path <- "/Users/bheavner/Desktop/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Normalized_Updated.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
path <- "/Users/bheavner/Desktop/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Normalized_Updated.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
path <- "/Users/bheavner/Desktop/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Normalized_Updated.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
path <- "/Users/bheavner/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_GeneCounts_Normalized_Updated.txt"
geneCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(geneCounts)
geneCounts[1,1]
write.table(format(geneCounts, scientific = FALSE, digits = 5),
path, quote = FALSE, sep = "\t", row.names = TRUE, col.names = NA)
system(paste("gzip", path, sep = " "))
path <- "/Users/bheavner/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_TranscriptCounts_Transposed_Updated.txt"
path <- "/Users/bheavner/Desktop/AMP-AD_TAUAPPms_UFL-Mayo-ISB_IlluminaHiSeq2000_Tau_TranscriptCounts_Transposed_Updated.txt"
transcriptCounts <- read.table(path, header = TRUE, check.names = FALSE)
colnames(transcriptCounts)
colnames(transcriptCounts) <- sub('P_', 'P', colnames(transcriptCounts))
colnames(transcriptCounts) <- sub('_', '.', colnames(transcriptCounts))
colnames(transcriptCounts)
write.table(transcriptCounts, path, quote = FALSE, sep = " ", row.names = TRUE, col.names = NA)
system(paste("gzip", path, sep = " "))
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("https://github.com/TODO")
mergedCountFile  <- 'syn3910523'
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE, check.names = FALSE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(Counts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name) #legacy?
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, scientific = FALSE, digits = 5), newFileName, quote = FALSE, sep = "\t", row.names = TRUE, col.names = NA)
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
q()
