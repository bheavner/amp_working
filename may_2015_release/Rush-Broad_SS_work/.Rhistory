JNPL3 <- DGEList(counts = JNPL3Counts, group = group)
dim(JNPL3)
keep <- rowSums(cpm(JNPL3)>100) >= 2
d <- JNPL3[keep,]
dim(d)
#3133   24
d$samples$lib.size <- colSums(d$counts)
d <- calcNormFactors(d, method = "TMM")
plotMDS(d, method="bcv", col=as.numeric(d$samples$group))
legend("bottomleft", as.character(unique(d$samples$group)), col=1:3, pch=20)
design.mat <- model.matrix(~0 + targets$Genotype + targets$Genotype:targets$Age)
design.mat
colnames(design.mat)
targets
design.mat <- model.matrix(~0 + targets$Genotype + targets$Genotype:targets$Age)
colnames(design.mat)
factor(paste(targets$Age, targets$Genotype, sep=""))
testGroup <- factor(paste(targets$Age, targets$Genotype, sep=""))
testDesign.mat <- model.matrix(~0 + group)
testDesign.mat
design.mat
colnames(design.mat)
class(design.mat)
twoPlus <- c(rep(0, length(design.mat[1,])))
twoPlus
twoPlus <- c(rep(0, length(design.mat[,1])))
twoPlus
targets
twoPlus[16]
twoPlus[16] <- 1
twoPlus
twoPlus[17] <- 1
twoPlus[24] <- 1
q()
require(synapseClient)
synapseLogin()
#query the knowledge portal for all the mayo/ufl/isb data
df <- synQuery('select name,id from file where projectId==\'syn2580853\' and center==\'UFL-Mayo-ISB\'')
#grab all the synapse objects for all mayo/ufl/isb data, but don't download the data
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
#extract internal Synapse id from provenance of all files, and add it to the df table
mayoProvenance <- lapply(synapseEntity,function(x){return(synGetActivity(x))})
file.oldId <- sapply(mayoProvenance,function(x){return(x$used[[1]]$reference$targetId)})
df <- cbind(df,file.oldId)
df <- synQuery('select name,id from file where projectId==\'syn2580853\' and center==\'UFL-Mayo-ISB\'')
df
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
onWeb('syn3205812')
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
onWeb('syn3207163')
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
mayoProvenance <- lapply(synapseEntity,function(x){return(synGetActivity(x))})
file.oldId <- sapply(mayoProvenance,function(x){return(sapply(x$used,function(x){return(x$reference$targetId)}))})
names(file.oldId) <- df$file.id
df
file.oldId
sort(df$file.id)
q()
q()
library(synapseClient) # for synapse upload
library(RCurl) # to grab google doc covariates files
source("uploadToSynapse.R")
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# Tau covariates are:"Mouse_ID" "Experiment" "RIN" "Genotype" "Sex" "Age_months" "RLIMS.ID" "Seq.Run.ID" "Lane.Number" "Clusters" "Raw_RNAseq_file_name"
# excel summary files on google drive - permissions are set to "anyone with link can view"
# file “20141209 Taner mouse-mRNA Summary.xlsx”  includes Mouse_ID, Seq.Run.ID, Lane.Number, Clusters, RLIMS.ID; part of the Raw_RNAseq_file_name (based on Seq Run ID); it's at
url1 <- getURL("https://docs.google.com/spreadsheets/d/1IQnJheILYLsUgWbwPT7Qmrmi-JngK0R3HTAJUfBYRUg/export?format=csv")
# “Copy of APP Randomization 9-16-14.xlsx” includes mouse_ID, Line == Experiment, RIN, Genotype (to transform), Sex, age in months; it's at
url2 <- getURL("https://docs.google.com/spreadsheets/d/1X_QRh-xw8q3lZ8IOosHdydxUsoP2Ucgxbfbk0FzMJx4/export?format=csv")
rawCovariates1 <- read.csv(textConnection(url1))
rawCovariates2 <- read.csv(textConnection(url2))
#remove first row of rawCovariates2 (all blanks)
rawCovariates2 <- rawCovariates2[2:129,]
APPCovariates = data.frame("Mouse_ID" = rawCovariates2$Mouse.ID)
#will need to check that these IDs agree with IDs in readcount data
APPCovariates <- cbind(APPCovariates, "Experiment" = rawCovariates2$Line)
APPCovariates <- cbind(APPCovariates, "RIN" = rawCovariates2$RIN)
APPCovariates <- cbind(APPCovariates, "Genotype" = rawCovariates2$Genotype)
APPCovariates <- cbind(APPCovariates, "Sex" = rawCovariates2$Sex)
APPCovariates <- cbind(APPCovariates, "Age_months" = rawCovariates2$Age)
#note: everything so far is from rawCovariates2, so when getting something from rawCovariates1, be sure it's in the right order
APPCovariates <- cbind(APPCovariates, "RLIMS.ID" =
rawCovariates1$RLIMS.ID[match(APPCovariates$Mouse_ID,
rawCovariates1$Sample.Name)])
APPCovariates <- cbind(APPCovariates, "Seq.Run.ID" =
rawCovariates1$Seq.Run.ID[match(APPCovariates$Mouse_ID,
rawCovariates1$Sample.Name)])
APPCovariates <- cbind(APPCovariates, "Lane.Number" =
rawCovariates1$Lane.Number[match(APPCovariates$Mouse_ID,
rawCovariates1$Sample.Name)])
APPCovariates <- cbind(APPCovariates, "Clusters" =
rawCovariates1$Clusters[match(APPCovariates$Mouse_ID,
rawCovariates1$Sample.Name)])
View(APPCovariates)
View(APPCovariates)
View(rawCovariates1)
View(rawCovariates1)
View(rawCovariates2)
View(rawCovariates2)
library(RCurl) # to grab google doc covariates files
library(gdata) # to read .xlsx file -  install.packages("gdata")
library(synapseClient) # for synapse upload
synapseLogin()
fullSampleInformation <- synGet("syn3163262")
fullSampleInformationFilePath <- getFileLocation(fullSampleInformation)
fullSample <- read.xls(fullSampleInformationFilePath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
#mayo_tcx_rnaseq_clinical_vars.txt syn3163736
# censored: has participant_id, age_at_last_assessment for some samples, sex, Braak
clinicalVars <- synGet("syn3163736")
clinicalVarsFilePath <- getFileLocation(clinicalVars)
clinical <- read.table(clinicalVarsFilePath, header = TRUE, stringsAsFactors = FALSE)
#mayo_tcx_rnaseq_tech_vars.txt syn3163738
techVars <- synGet("syn3163738")
techVarsFilePath <- getFileLocation(techVars)
# has RNASubjectID, RNAId, Source, tissue, RIN
tech <- read.table(techVarsFilePath, header = TRUE, stringsAsFactors = FALSE)
sampleGroups <- synGet("syn3163739")
#mayo_tcx_rnaseq_sample_groups.txt syn3163739
# may not need
sampleGroupsFilePath <- getFileLocation(sampleGroups)
groups <- read.table(sampleGroupsFilePath, header = TRUE, stringsAsFactors = FALSE)
rerunSamples  <- synGet("syn3523879")
rerunSamplesFilePath <- getFileLocation(rerunSamples)
rerun <- read.xls(rerunSamplesFilePath, sheet = 2, header = TRUE, stringsAsFactors = FALSE)
rushBroadCovariates  <- data.frame()
rushBroadCovariates$Samples <- fullSample[fullSample$Source == "RUSH-BROAD", "RNASubjectId"]
rawCovariates2 <- rawCovariates2[2:129,]
library(synapseClient) # for synapse upload
library(RCurl) # to grab google doc covariates files
library(gdata) # to read .xlsx file
library(dplyr) # for subsetting data
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
fullSampleInformation <- synGet("syn3163262")
fullSampleInformationFilePath <- getFileLocation(fullSampleInformation)
fullSample <- read.xls(fullSampleInformationFilePath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
rerunSamples  <- synGet("syn3523879")
rerunSamplesFilePath <- getFileLocation(rerunSamples)
rerun <- read.xls(rerunSamplesFilePath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
rushBroadSamples <- fullSample[fullSample$Source == "RUSH-BROAD", "RNASubjectId"]
length(rushBroadSamples) #10
length(intersect(rushBroadSamples, rerun$SubjectID)) #10 - so all of them!
rushBroadFile1 <- rerun[fullSample$Source == "RUSH-BROAD", "DriveA_FileName1"]
rushBroadFile2 <- rerun[fullSample$Source == "RUSH-BROAD", "DriveA_FileName2"]
rushBroadFile3 <- rerun[fullSample$Source == "RUSH-BROAD", "DriveB_FileName1"]
rushBroadFile4 <- rerun[fullSample$Source == "RUSH-BROAD", "DriveB_FileName2"]
rushBroadFiles <- c(rushBroadFile1[rushBroadFile1 != "NULL"],
rushBroadFile2[rushBroadFile2 != "NULL"],
rushBroadFile3[rushBroadFile3 != "NULL"],
rushBroadFile4[rushBroadFile4 != "NULL"])
rushBroadFiles
fullSample[fullSample$Source == "RUSH-BROAD", "RNASubjectId"]
sampleSwapIds <- c("10249336", "50100518", "50104008", "20177982", "36492755",
"05689621", "11444465", "10315029", "20270920", "11615242")
sampleSwapIds
q()
q()
gene1 <- NA;
is.null(gene1)
?is.null
q()
library(dplyr) # for subsetting data
library(R.utils) # for unzipping data
library(synapseClient) # to download data
library(edgeR) # for DE analysis
library(biomaRt) # for gene name lookups
library(ggplot2) # for better boxplots
library(reshape2) # for melt for ggplot
library(PerformanceAnalytics) # for kertosis calculations
## Get data and define groups
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# get the transposed readcount file and covariates file from synapse
countFile <- synGet('syn3192634')
covariatesFile <- synGet('syn2875343') # the working dir copy
# unzip count file and load for processing
localCountFilePath <- getFileLocation(countFile)
if(!file.exists(sub('.gz', '', localCountFilePath))) {
gunzip(localCountFilePath)
}
localCountFilePath <- sub('.gz', '', localCountFilePath) #trim the .gz suffix
counts <- read.table(localCountFilePath, header = TRUE, stringsAsFactors = FALSE)
#PROBLEM: - an rTGMinus sample
#in count data, sample “LP62_4”
#in covariates, sample “LP_62_4”
# for now, change column name in counts - TODO: fix covariates file
colnames(counts)[1] <- "LP_62_4"
# load covariates file to have handy
covariates <- read.table(getFileLocation(covariatesFile), header = TRUE, stringsAsFactors = FALSE)
## define groups: JNPL3+ (transgenic), JNPL3- (WT), (ignore rTG+ rTG- for now)
# (there MUST be a cleaner way to do this)
# JNPL3+:
JNPL3Plus <- dplyr::select(filter(covariates, Experiment == "MAPT_P301L" & Genotype == "+"), Mouse_ID)
# 15 samples
# JNPL3-:
JNPL3Minus <- dplyr::select(filter(covariates, Experiment == "MAPT_P301L" & Genotype == "-"), Mouse_ID)
# 9 samples
JNPL3Plus <- as.character(JNPL3Plus$Mouse_ID)
JNPL3Minus <- as.character(JNPL3Minus$Mouse_ID)
JNPL3PlusCols <- is.element(as.character(colnames(counts)), JNPL3Plus)
JNPL3MinusCols <- is.element(as.character(colnames(counts)), JNPL3Minus)
groups <- c(rep(0, length(counts[1,])))
groups[JNPL3PlusCols] <- "JNPL3Plus"
groups[JNPL3MinusCols] <- "JNPL3Minus"
JNPL3Samples <- c(JNPL3Plus, JNPL3Minus)
JNPL3Cols <- is.element(as.character(colnames(counts)), JNPL3Samples)
## Make DGEList object to start working on DE analysis
JNPL3 <- DGEList(counts = dplyr::select(counts, one_of(JNPL3Samples)),
group = groups[JNPL3Cols])
## filter data
# require minimum of 100 counts per million for at least 2 samples
d.full <- JNPL3 # keep the old one in case we mess up
dim(d.full)
#39179    24
keep <- rowSums(cpm(JNPL3)>100) >= 2
d <- JNPL3[keep,]
dim(d)
#3133   24 #seth says this is too stringent - 70% of genes in genome are expressed in brain - ~20k features normal
# reset library sizes after filtering
d$samples$lib.size <- colSums(d$counts)
# normalize the data using TMM
d <- calcNormFactors(d, method = "TMM")
plotMDS(d, method="bcv", col=as.numeric(d$samples$group))
legend("bottomleft", as.character(unique(d$samples$group)), col=1:3, pch=20)
d1 <- estimateCommonDisp(d, verbose=T) #assume all same for this pass, GLM later
# Disp = 0.09527 , BCV = 0.3087
d1 <- estimateTagwiseDisp(d1)
plotBCV(d1) #plots the tagwise biological coefficient of variation (square root of dispersions) against log2-CPM.
# observation - looks like a discontinuity in the dispersions around logCPM ~ 7
# Look at DE with exact test
de.tgw <- exactTest(d1)
summary(decideTestsDGE(de.tgw, p.value=0.01))
topTen <- rownames(topTags(de.tgw, n = 10))
toPlot <- d[topTen] #10 rows, 24 columns
top <- topTags(de.tgw, n=50)
# get gene names for x axis labels -- ORDER ISN'T PRESERVED FROM BIOMART QURY!
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = rownames(top)[1:10],
ensembl)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = rownames(top)[1:100],
ensembl)
geneNames
top <- topTags(de.tgw, n=100)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = rownames(top)[1:100], ensembl)
top
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
ensemblToGeneId(rownames(top), ensembl)
geneNames[1,]
labels <- geneNames$external_gene_name[(order(match(geneNames$ensembl_gene_id, rownames(top)[1:10])))]
labels(1)
labels[1]
values
rownames(top)[1:100]
geneIds <- rep(NA,100)
geneIds <- values
geneIds <- rownames(top)[1:100]
geneIds
write(geneIds, "testIds.txt")
pwd
system(ls)
system('ls')
geneIds <- read.table("testIds.txt")
View(geneIds)
View(geneIds)
require(biomaRt)
geneIds <- read.table("testIds.txt")
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
testNames <- ensemblToGeneId(geneIds, ensembl)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = geneIds, ensembl)
geneNames[1]
geneNames$external_gene_name[1]
geneIds[1]
geneIds$V1[1]
as.character(geneIds$V1[1])
geneNames$ensembl_gene_id[1]
geneNames
geneNames$external_gene_name[1]
testNames[1]
testNames$external_gene_name[1]
geneNames[(order(match(geneNames$ensembl_gene_id, geneIds)))]
geneNames[(order(match(geneNames$ensembl_gene_id, geneIds))),]
geneNames <- geneNames[(order(match(geneNames$ensembl_gene_id, geneIds)))]
geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
geneNames <- geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
unique(geneIds)
setdif(geneIds, geneNames$ensembl_gene_id)
geneIds &in& geneNames$ensembl_gene_id
geneIds %in% geneNames$ensembl_gene_id
geneIds %in% geneNames$ensembl_gene_id[,]
geneIds %in% geneNames$ensembl_gene_id
setdiff(geneIds, geneNames$ensembl_gene_id)
setdiff(geneIds, as.list(geneNames$ensembl_gene_id))
geneNames$ensembl_gene_id
?setdiff
?setdiff
as.vector(geneNames$ensembl_gene_id)
setdiff(geneIds, as.vector(geneNames$ensembl_gene_id))
setdiff(as.vector(geneIds), as.vector(geneNames$ensembl_gene_id))
class(geneIds)
class(geneName)
geneIds
setdiff(as.vector(geneIds$V1), as.vector(geneNames$ensembl_gene_id))
geneIds
geneIds == "ENSMUSG00000019769"
geneNames[1]
geneNames$V1[1]
geneNames$ensembl_gene_id[1]
geneIds[1]
geneIds$V1[1]
geneNames$ensembl_gene_id[1]
require(biomaRt)
geneIds <- read.table("testIds.txt")
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
# use function to get gene name by ensembl_gene_id
testNames <- ensemblToGeneId(geneIds, ensembl)
# or grab them directly without the function
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = geneIds, ensembl)
geneIds[1]
geneIds$V1[1]
geneNames$ensembl_gene_id[1]
testNames[1]
testNames$external_gene_name[1]
as.character(geneIds$V1[1]) # ENSMUSG00000061808
geneIds$V1[1]
geneNames$ensembl_gene_id[1] # ENSMUSG00000001025
geneNames$external_gene_name[1] # "S100a6"
testNames$external_gene_name[1] # "S100a6" -- NOT WHAT I'D EXPECT WHEN CALLING FUNCTION
geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
match(geneNames$ensembl_gene_id, geneIds)
order(match(geneNames$ensembl_gene_id, geneIds)
)
match(geneNames$ensembl_gene_id, geneIds)
?match
match(as.vector(geneNames$ensembl_gene_id), geneIds)
match(as.vector(geneNames$ensembl_gene_id), as.vector(geneIds))
as.vector(geneIds)
geneNames$ensembl_gene_id
match(geneNames$ensembl_gene_id, geneIds)
match(geneIds, geneNames$ensembl_gene_id)
q()
setwd("~/Projects/UO1-AMP/working/may_2015_release/Rush-Broad_SS_work")
sampleSwapIds <- c("10249336", "50100518", "50104008", "20177982", "36492755",
"05689621", "11444465", "10315029", "20270920", "11615242")
for (index in 1:length(sampleSwapIds) ) {
system(paste("aws s3 ls s3://mayo-u01-rnaseq/snapr/|grep",
sampleSwapIds[index],
">> processOutput.txt"))
}
processedFiles <- read.table("processOutput.txt", stringsAsFactors = FALSE)
processedFiles
for (index in 1:length(sampleSwapIds) ) {
system(paste("aws s3 ls s3://mayo-u01-rnaseq/rush_broad_ss//|grep",
sampleSwapIds[index],
">> processOutput.txt"))
}
processedFiles <- read.table("processOutput.txt", stringsAsFactors = FALSE)
processedFiles
numMissed  <- length(sampleSwapIds) - (nrow(processedFiles) / 12)
numMissed
# which is missing?
outputs  <- rep(NA,length(sampleSwapIds))
if(numMissed > 0) {
for (index in 1:length(sampleSwapIds) ) {
outputs[index]  <- sum(grepl(sampleSwapIds[index], processedFiles$V4))
}
}
outputs
sampleSwapIds[!as.logical(outputs)]
processedFiles$V4
processedFiles
for (index in 1:length(sampleSwapIds) ) {
system(paste("aws s3 ls s3://mayo-u01-rnaseq/rush_broad_ss/|grep",
sampleSwapIds[index],
">> processOutput.txt"))
}
processedFiles <- read.table("processOutput.txt", stringsAsFactors = FALSE)
processedFiles
for (index in 1:length(sampleSwapIds) ) {
system(paste("aws s3 ls s3://mayo-u01-rnaseq/rush_broad_ss/snapr/|grep",
sampleSwapIds[index],
">> processOutput.txt"))
}
processedFiles <- read.table("processOutput.txt", stringsAsFactors = FALSE)
numMissed  <- length(sampleSwapIds) - (nrow(processedFiles) / 12)
numMissed
processedFiles
69/7
sort(sampleSwapIds)
library(synapseClient)
library(tools)
source("merge_count_files.R")
# Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
rushBroadSS_rnaseq_counts <- "syn3619668" # all count files in a zipped directory
# Download files from Synapse
rushBroadSS_count_files <- synGet(rushBroadSS_rnaseq_counts)
rushBroadSS_files_path <- getFileLocation(rushBroadSS_count_files)
rushBroadSS_files_path
fileDir <- file_path_sans_ext(basename(rushBroadSS_files_path))
tmpDir <- tempdir()
tmpDir
?tempdir
unzip(rushBroadSS_files_path, exdir = tmpDir)
past('foo', 'bar' sep="")
past('foo', 'bar', sep="")
paste('foo', 'bar', sep="")
paste(tmpDir, '/tmp/ss', sep = "")
fileDir
inputDir <- paste(tmpDir, '/tmp/ss', sep = "")
prefix <- "AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_Rush-Broad-SS"
countTypes <- c("gene_id", "transcript_id")
for (countType in countTypes) {
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = psp_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
for (countType in countTypes) {
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = rushBroadSS_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
library(synapseClient)
library(tools)
source("merge_count_files.R")
# Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# Define paths for required Synapse objects
rushBroadSS_rnaseq_counts <- "syn3619668" # all count files in a zipped directory
# Download files from Synapse
rushBroadSS_count_files <- synGet(rushBroadSS_rnaseq_counts)
rushBroadSS_files_path <- getFileLocation(rushBroadSS_count_files)
# Get name of temporary directory to store unzipped files (same as name of
# original compressed directory)
fileDir <- file_path_sans_ext(basename(rushBroadSS_files_path))
tmpDir <- tempdir()
unzip(rushBroadSS_files_path, exdir = tmpDir)
tmpDir
inputDir <- paste(tmpDir, '/tmp/ss', sep = "")
inputDir
library(synapseClient)
library(tools)
source("merge_count_files.R")
# Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# Define paths for required Synapse objects
rushBroadSS_rnaseq_counts <- "syn3619668" # all count files in a zipped directory
# Download files from Synapse
rushBroadSS_count_files <- synGet(rushBroadSS_rnaseq_counts)
rushBroadSS_files_path <- getFileLocation(rushBroadSS_count_files)
# Get name of temporary directory to store unzipped files (same as name of
# original compressed directory)
fileDir <- file_path_sans_ext(basename(rushBroadSS_files_path))
tmpDir <- tempdir()
unzip(rushBroadSS_files_path, exdir = tmpDir)
inputDir <- paste(tmpDir, '/tmp/ss', sep = "")
inputDir
#inputDir <- file.path(tmpDir, fileDir)
prefix <- "AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_dIPFC_Rush-Broad-SS"
countTypes <- c("gene_id", "transcript_id") #
for (countType in countTypes) {
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = rushBroadSS_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
exit
q()
