setwd('/Volumes/magis1/Snap/Final_Results/STAD_counts');

library(edgeR)
library(limma)
stringsAsFactors = FALSE;

# Read in the count data
targets <- read.delim(file = "Targets.txt");
dge <- readDGE(targets, header=F)

# Calculate normalization factors
dge <- calcNormFactors(dge)

# Calculate FPM with all genes
fpm <- cpm(dge);

# Eliminate genes with too few counts for samples
ridx <- rowSums(fpm > 1) >= 5
dge$counts <- dge$counts[ridx,]

# Eliminate genes with too-low read counts
dge <- dge[rowSums(dge$counts) >= 100,]

# TAYLOR YOU NEED TO EDIT THIS PART TO SELECT YOUR GROUPS
# Here I pick groups based on EBV read counts, but you can select groups 
# according to some other metric
sets = rep("None", dim(targets)[1]);
colors = rep("black", dim(targets)[1]);
EBV1_high = targets$EBV1 > 10000;
EBV1_low = targets$EBV1 == 0 & targets$EBV2 == 0 & targets$CMV == 0;

sets[EBV1_high] = "EBV1_high";
sets[EBV1_low] = "EBV1_low";
colors[EBV1_high] = "red";
colors[EBV1_low] = "blue";

# Multidimensional scaling plot to visualize the samples
plotMDS(dge, col=colors, top=100)
title("MDS Plot: Top 100 Probes")

group = factor(sets, levels=c("EBV1_high", "EBV1_low", "None"));

# Build the model matrix for fitting a linear model and estimate fit parameters
design <- model.matrix(~0+group)
rownames(design) <- group;
dge <- estimateGLMCommonDisp(dge,design)
dge <- estimateGLMTagwiseDisp(dge,design)
fit <- glmFit(dge,design, dispersion=dge$tagwise.dispersion)

# Pvalue
pval = 0.01;

save(list=c("dge", "fit", "design", "fpm", "pval", "targets", "group"), file="STAD.new.RData");

# Actually perform the differential expression comparison
ebv.noebv <- glmLRT(fit,contrast=c(1,-1,0))
summary(decideTestsDGE(ebv.noebv, p.value=pval))
topTags(ebv.noebv, n=10)
de.ebv.noebv = topTags(ebv.noebv, n=50000)$table

# LogFC filtering and save 
index <- de.ebv.noebv$logFC > 1 | de.ebv.noebv$logFC < -1
de.fc.ebv.noebv <- de.ebv.noebv[index,];
write.csv(de.fc.ebv.noebv, file='de.fc.ebv.noebv.csv');


###### CMA for cross-validation between the two groups

library(CMA);
library(edgeR);

data = cpm(dge);

EBV1_high = targets$EBV1 > 1000;
EBV1_low = targets$EBV1 == 0 & targets$EBV2 == 0 & targets$CMV == 0;

dataY = factor(c(rep("high", sum(EBV1_high)), rep("low", sum(EBV1_low))));
dataX = t(as.matrix(data[,EBV1_high | EBV1_low]));

############# CHOOSE ONE OF THESE (UNCOMMENT)

# Generate learning sets for 5-fold cross validation  (leave out 20% as test set) repeated 100 times
CV <- GenerateLearningsets(y=dataY, method="CV", fold=10, niter=10, strat=TRUE)

# Generate learning sets for leave-one-out cross validation (less robust)
#CV <- GenerateLearningsets(y=dataY, method="LOOCV")

##############################################

############# CHOOSE ONE OF THESE (UNCOMMENT)

# Support Vector Machine (SVM) 
varsel_CV <- GeneSelection(X=dataX, y=dataY, learningsets = CV, method = "t.test")

show(varsel_CV)
toplist(varsel_CV, iter = 1)
seliter <- numeric()
for (i in 1:100) seliter <- c(seliter, toplist(varsel_CV, iter = i, top = 10, show = FALSE)$index) 
genes = sort(table(seliter), dec = TRUE)
classifier <- as.numeric(rownames(genes)[1:10])
all_genes <- colnames(dataX);
all_genes[classifier];


# Get these genes
class_CV <- classification(X=dataX, y=dataY, genesel=varsel_CV, learningsets=CV, classifier=svmCMA, nbgene=10, cost=0.1, probability=T)

# Linear Discriminant Analysis (LDA)
# class_CV <- classification(X=dataX, y=dataY, learningsets=CV, classifier=ldaCMA)

##############################################

# Print the confusion matrix
resultlist <- list(class_CV);
result <- lapply(resultlist, join) 
invisible(lapply(result, ftable)) 

# Print the ROC curve
for(i in seq(along = result)) roc(result[[i]])

