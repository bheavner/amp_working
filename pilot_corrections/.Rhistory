groups <- c(rep(0, length(counts[1,])))
groups[JNPL3PlusCols] <- "JNPL3Plus"
groups[JNPL3MinusCols] <- "JNPL3Minus"
JNPL3Samples <- c(JNPL3Plus, JNPL3Minus)
JNPL3Cols <- is.element(as.character(colnames(counts)), JNPL3Samples)
## Make DGEList object to start working on DE analysis
JNPL3 <- DGEList(counts = dplyr::select(counts, one_of(JNPL3Samples)),
group = groups[JNPL3Cols])
## filter data
# require minimum of 100 counts per million for at least 2 samples
d.full <- JNPL3 # keep the old one in case we mess up
dim(d.full)
#39179    24
keep <- rowSums(cpm(JNPL3)>100) >= 2
d <- JNPL3[keep,]
dim(d)
#3133   24 #seth says this is too stringent - 70% of genes in genome are expressed in brain - ~20k features normal
# reset library sizes after filtering
d$samples$lib.size <- colSums(d$counts)
# normalize the data using TMM
d <- calcNormFactors(d, method = "TMM")
plotMDS(d, method="bcv", col=as.numeric(d$samples$group))
legend("bottomleft", as.character(unique(d$samples$group)), col=1:3, pch=20)
d1 <- estimateCommonDisp(d, verbose=T) #assume all same for this pass, GLM later
# Disp = 0.09527 , BCV = 0.3087
d1 <- estimateTagwiseDisp(d1)
plotBCV(d1) #plots the tagwise biological coefficient of variation (square root of dispersions) against log2-CPM.
# observation - looks like a discontinuity in the dispersions around logCPM ~ 7
# Look at DE with exact test
de.tgw <- exactTest(d1)
summary(decideTestsDGE(de.tgw, p.value=0.01))
topTen <- rownames(topTags(de.tgw, n = 10))
toPlot <- d[topTen] #10 rows, 24 columns
top <- topTags(de.tgw, n=50)
# get gene names for x axis labels -- ORDER ISN'T PRESERVED FROM BIOMART QURY!
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = rownames(top)[1:10],
ensembl)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = rownames(top)[1:100],
ensembl)
geneNames
top <- topTags(de.tgw, n=100)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = rownames(top)[1:100], ensembl)
top
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
ensemblToGeneId(rownames(top), ensembl)
geneNames[1,]
labels <- geneNames$external_gene_name[(order(match(geneNames$ensembl_gene_id, rownames(top)[1:10])))]
labels(1)
labels[1]
values
rownames(top)[1:100]
geneIds <- rep(NA,100)
geneIds <- values
geneIds <- rownames(top)[1:100]
geneIds
write(geneIds, "testIds.txt")
pwd
system(ls)
system('ls')
geneIds <- read.table("testIds.txt")
View(geneIds)
View(geneIds)
require(biomaRt)
geneIds <- read.table("testIds.txt")
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
testNames <- ensemblToGeneId(geneIds, ensembl)
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = geneIds, ensembl)
geneNames[1]
geneNames$external_gene_name[1]
geneIds[1]
geneIds$V1[1]
as.character(geneIds$V1[1])
geneNames$ensembl_gene_id[1]
geneNames
geneNames$external_gene_name[1]
testNames[1]
testNames$external_gene_name[1]
geneNames[(order(match(geneNames$ensembl_gene_id, geneIds)))]
geneNames[(order(match(geneNames$ensembl_gene_id, geneIds))),]
geneNames <- geneNames[(order(match(geneNames$ensembl_gene_id, geneIds)))]
geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
geneNames <- geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
unique(geneIds)
setdif(geneIds, geneNames$ensembl_gene_id)
geneIds &in& geneNames$ensembl_gene_id
geneIds %in% geneNames$ensembl_gene_id
geneIds %in% geneNames$ensembl_gene_id[,]
geneIds %in% geneNames$ensembl_gene_id
setdiff(geneIds, geneNames$ensembl_gene_id)
setdiff(geneIds, as.list(geneNames$ensembl_gene_id))
geneNames$ensembl_gene_id
?setdiff
?setdiff
as.vector(geneNames$ensembl_gene_id)
setdiff(geneIds, as.vector(geneNames$ensembl_gene_id))
setdiff(as.vector(geneIds), as.vector(geneNames$ensembl_gene_id))
class(geneIds)
class(geneName)
geneIds
setdiff(as.vector(geneIds$V1), as.vector(geneNames$ensembl_gene_id))
geneIds
geneIds == "ENSMUSG00000019769"
geneNames[1]
geneNames$V1[1]
geneNames$ensembl_gene_id[1]
geneIds[1]
geneIds$V1[1]
geneNames$ensembl_gene_id[1]
require(biomaRt)
geneIds <- read.table("testIds.txt")
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
ensemblToGeneId <- function(x,ensembl){
gene1 <- NA;
try(gene1 <- getBM(attributes='external_gene_name',filters='ensembl_gene_id',values=x,mart=ensembl),silent=T)
if(is.null(gene1)){
gene1<-NA
}
return(gene1)
}
# use function to get gene name by ensembl_gene_id
testNames <- ensemblToGeneId(geneIds, ensembl)
# or grab them directly without the function
geneNames <- getBM(c("ensembl_gene_id", "external_gene_name"),
filters = "ensembl_gene_id",
values = geneIds, ensembl)
geneIds[1]
geneIds$V1[1]
geneNames$ensembl_gene_id[1]
testNames[1]
testNames$external_gene_name[1]
as.character(geneIds$V1[1]) # ENSMUSG00000061808
geneIds$V1[1]
geneNames$ensembl_gene_id[1] # ENSMUSG00000001025
geneNames$external_gene_name[1] # "S100a6"
testNames$external_gene_name[1] # "S100a6" -- NOT WHAT I'D EXPECT WHEN CALLING FUNCTION
geneNames[order(match(geneNames$ensembl_gene_id, geneIds)),]
match(geneNames$ensembl_gene_id, geneIds)
order(match(geneNames$ensembl_gene_id, geneIds)
)
match(geneNames$ensembl_gene_id, geneIds)
?match
match(as.vector(geneNames$ensembl_gene_id), geneIds)
match(as.vector(geneNames$ensembl_gene_id), as.vector(geneIds))
as.vector(geneIds)
geneNames$ensembl_gene_id
match(geneNames$ensembl_gene_id, geneIds)
match(geneIds, geneNames$ensembl_gene_id)
q()
library(synapseClient) # for synapse upload
library(RCurl) # to grab google doc covariates files
library(gdata) # to read .xlsx file -  install.packages("gdata")
fullSampleInformation <- synGet("syn3163262")
fullSampleInformationFilePath <- getFileLocation(fullSampleInformation)
fullSample <- read.xls(fullSampleInformationFilePath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
synapseLogin()
fullSampleInformation <- synGet("syn3163262")
fullSampleInformationFilePath <- getFileLocation(fullSampleInformation)
fullSample <- read.xls(fullSampleInformationFilePath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
View(fullSample)
#mayo_tcx_rnaseq_clinical_vars.txt syn3163736
# censored: has participant_id, age_at_last_assessment for some samples, sex, Braak
clinicalVars <- synGet("syn3163736")
clinicalVarsFilePath <- getFileLocation(clinicalVars)
clinical <- read.table(clinicalVarsFilePath, header = TRUE, stringsAsFactors = FALSE)
View(clinical)
#mayo_tcx_rnaseq_tech_vars.txt syn3163738
# has RNASubjectID, RNAId, Source, tissue, RIN
techVars <- synGet("syn3163738")
techVarsFilePath <- getFileLocation(techVars)
tech <- read.table(techVarsFilePath, header = TRUE, stringsAsFactors = FALSE)
View(tech)
sampleGroups <- synGet("syn3163739")
sampleGroupsFilePath <- getFileLocation(sampleGroups)
groups <- read.table(sampleGroupsFilePath, header = TRUE, stringsAsFactors = FALSE)
rerunSamples  <- synGet("syn3523879")
rerunSamplesFilePath <- getFileLocation(rerunSamples)
rerun <- read.xls(rerunSamplesFilePath, sheet = 2, header = TRUE, stringsAsFactors = FALSE)
View(rerun)
View(clinical)
View(tech)
View(tech)
View(rerun)
View(rerun)
View(fullSample)
View(fullSample)
View(clinical)
View(clinical)
View(fullSample)
View(rerun)
View(tech)
View(rerun)
setwd("~/Projects/UO1-AMP/working/pilot_corrections")
# This script uses the merging function saved in merge_file_counts.R to combine
# SNAPR count files for reprocessed pilot AD RNAseq data from Mayo
library(synapseClient)
library(tools)
source("merge_count_files.R")
# Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# Define paths for required Synapse objects
psp_rnaseq_counts <- "syn3578144" # all count files in a zipped directory
# Download files from Synapse
psp_count_files <- synGet(psp_rnaseq_counts)
psp_files_path <- getFileLocation(psp_count_files)
# Get name of temporary directory to store unzipped files (same as name of
# original compressed directory)
fileDir <- file_path_sans_ext(basename(psp_files_path))
tmpDir <- tempdir()
unzip(psp_files_path, exdir = tmpDir)
inputDir <- file.path(tmpDir, fileDir)
prefix <- "AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_"
countTypes <- c("gene_id", "transcript_id")
for (countType in countTypes) {
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = psp_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
fileDir
tempDir
tmpDir
tmpDir = "/var/folders/z3/bm39bty12lzfhhmmstkg7fkr0000gq/T//RtmpheMyxB/tmp"
for (countType in countTypes) {
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = psp_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
inputDir
inputDir <- file.path(tmpDir, fileDir)
for (countType in countTypes) {
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = psp_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
# fix IDs in PSP countfiles
library(gdata) # to read .xlsx file -  install.packages("gdata")
genePath = "/Users/bheavner/Desktop/psp/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_gene_id_counts_UpdatedID.txt"
geneCounts <- read.table(genePath, header = TRUE)
colnames(geneCounts)
keyPath  <- "/Users/bheavner/Desktop/Data\ errors/ToSend/PSP_MA_040915_IDsKey.xlsx"
keyHash <- read.xls(keyPath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
match(row.names(geneCounts), keyHash$Path_ID)
match(colnames(geneCounts), keyHash$Path_ID)
colnames(geneCounts)
sub('.', '-', colnames(GeneCounts))
sub('.', '-', colnames(geneCounts))
sub('\.', '-', colnames(geneCounts))
sub('X', '', colnames(geneCounts))
colnames(geneCounts)  <- sub('X', '', colnames(geneCounts))
?sub
sub('[.]:punct:]', '-', colnames(geneCounts))
sub('[.:punct:]', '-', colnames(geneCounts))
match(colnames(geneCounts), keyHash$Path_ID)
colnames(geneCounts)
colnames(geneCounts)  <- sub('X', '', colnames(geneCounts))
colnames(geneCounts)  <- sub('[.:punct:]', '-', colnames(geneCounts))
colnames(geneCounts)
match(colnames(geneCounts), keyHash$Path_ID)
colnames(geneCounts) <- keyHash$IlluminaSampleID[match(colnames(geneCounts), keyHash$Path_ID)]
colnames(geneCounts)
write.table(geneCounts, genePath) #, quote = FALSE, sep = " ", row.names = TRUE)
system(paste("gzip", genePath))
transcriptPath = "/Users/bheavner/Desktop/psp/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_transcript_id_counts_UpdatedID.txt"
transcriptCounts <- read.table(transcriptPath, header = TRUE)
colnames(transcriptCounts)
colnames(transcriptCounts)
colnames(transcriptCounts)  <- sub('X', '', colnames(transcriptCounts))
colnames(transcriptCounts)  <- sub('[.:punct:]', '-', colnames(transcriptCounts))
colnames(transcriptCounts)
colnames(transcriptCounts) <- keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
colnames(transcriptCounts)
write.table(transcriptCounts, genePath, quote = FALSE, sep = " ", row.names = TRUE)
system(paste("gzip", transcriptPath))
colnames(transcriptCounts) == "1811024331_B"
# This script normalizes the merged count_files produced by running merge_file_counts.R
# on SNAPR output. It does so by dowloading the merged read count files, processing them,
# and uploading new synapse objects with appropriate provenance.
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("https://github.com/PriceLab/AMP-ad/pilotCorrections/normalize_readcounts.R")
countFileSynapseIDs <- c('ssyn3583358', 'syn3583357')
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, digits=2),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
## TEST ABOVE
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
mergedCountFile <- 'syn3583358'
originalCountFile <- synGet(mergedCountFile)
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
expr$samples$lib.size
expr$samples
library(synapseClient)
library(tools)
source("merge_count_files.R")
# Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# Define paths for required Synapse objects
psp_rnaseq_counts <- "syn3578144" # all count files in a zipped directory
# Download files from Synapse
psp_count_files <- synGet(psp_rnaseq_counts)
psp_files_path <- getFileLocation(psp_count_files)
# Get name of temporary directory to store unzipped files (same as name of
# original compressed directory)
fileDir <- file_path_sans_ext(basename(psp_files_path))
tmpDir <- tempdir()
unzip(psp_files_path, exdir = tmpDir)
inputDir <- file.path(tmpDir, fileDir)
prefix <- "AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_"
countType <- "gene_id"
merged_file <- create_merged_file(inputDir, countType, prefix)
inputDir
list.files(inputDir, pattern = countType, recursive = TRUE)
inputDir <- /var/folders/z3/bm39bty12lzfhhmmstkg7fkr0000gq/T//RtmpheMyxB/tmp/psp-rnaseq-counts_Updated
inputDir <- "/var/folders/z3/bm39bty12lzfhhmmstkg7fkr0000gq/T//RtmpheMyxB/tmp/psp-rnaseq-counts_Updated"
merged_file <- create_merged_file(inputDir, countType, prefix)
merged_file <- create_merged_file(inputDir, countType, prefix)
merged_file_object <- File(path = merged_file,
parentId = psp_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
countType <- "transcript_id"
message(paste("Merging", prefix, "files of count type", countType, "..."))
# Create the merged file and store the output file path
merged_file <- create_merged_file(inputDir, countType, prefix)
# Create a Synapse object for the output file and upload
merged_file_object <- File(path = merged_file,
parentId = psp_count_files$properties$parentId)
merged_file_object <- synStore(merged_file_object)
}
library(gdata) # to read .xlsx file -  install.packages("gdata")
genePath = "/Users/bheavner/Desktop/psp/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_gene_id_counts_UpdatedID.txt"
geneCounts <- read.table(genePath, header = TRUE)
# colnames need to change to match the Path_ID
# remove leading X
colnames(geneCounts)  <- sub('X', '', colnames(geneCounts))
geneCounts <- read.table(genePath, header = TRUE)
colnames(geneCounts)
colnames(geneCounts)
colnames(geneCounts)
colnames(geneCounts)
colnames(geneCounts)
colnames(geneCounts)  <- sub('X', '', colnames(geneCounts))
#replace . with -
colnames(geneCounts)  <- sub('[.:punct:]', '-', colnames(geneCounts))
keyPath  <- "/Users/bheavner/Desktop/Data\ errors/ToSend/PSP_MA_040915_IDsKey.xlsx"
keyHash <- read.xls(keyPath, sheet = 1, header = TRUE, stringsAsFactors = FALSE)
# replace colnames(geneCounts) with corresponding keyHash$IlluminaSampleID values
colnames(geneCounts) <- keyHash$IlluminaSampleID[match(colnames(geneCounts), keyHash$Path_ID)]
colnames(geneCounts)
write.table(geneCounts, genePath) #, quote = FALSE, sep = " ", row.names = TRUE)
#test <- read.table(genePath, header = TRUE)
system(paste("gzip", genePath))
# then upload it to synapse
transcriptPath = "/Users/bheavner/Desktop/psp/AMP-AD_MayoPilot_UFL-Mayo-ISB_IlluminaHiSeq2000_TemporalCortex_ProgressiveSupranuclearPalsy_transcript_id_counts_UpdatedID.txt"
transcriptCounts <- read.table(transcriptPath, header = TRUE)
# colnames need to change to match the Path_ID
# remove leading X
colnames(transcriptCounts)  <- sub('X', '', colnames(transcriptCounts))
#replace . with -
colnames(transcriptCounts)  <- sub('[.:punct:]', '-', colnames(transcriptCounts))
# replace colnames(transcriptCounts) with corresponding keyHash$IlluminaSampleID values
colnames(transcriptCounts) <- keyHash$IlluminaSampleID[match(colnames(transcriptCounts), keyHash$Path_ID)]
# save and rezip the geneCounts table.
write.table(transcriptCounts, genePath, quote = FALSE, sep = " ", row.names = TRUE)
#test <- read.table(genePath, header = TRUE)
system(paste("gzip", transcriptPath))
transposedCounts  <- geneCounts
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
mergedCountFile <- 'syn3583369'
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("https://github.com/PriceLab/AMP-ad/pilotCorrections/normalize_readcounts.R")
originalCountFile <- synGet(mergedCountFile)
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
normFactors <- calcNormFactors(expr, method = ("TMM"))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, digits=2),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
?format
getOption("digits"
)
write.table(format(normalizedCpm),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
write.table(format(normalizedCpm, scientific = FALSE),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
mergedCountFile  <- 'syn3583368'
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
transposedCounts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(transposedCounts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
normalizedCpm <- cpm(normFactors)
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(format(normalizedCpm, scientific = FALSE, digits = 5),
newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
gzip(newFileName)
q()
