toPlot$data
toPlot%groups
toPlot$groups
toPlot$group
head(toPlot)
toPlot$counts
toPlot$samples
ggplot(toPlot$counts) + geom_boxplot
boxplot(toPlot$counts), use.cols = FALSE)
boxplot(toPlot$counts, use.cols = FALSE)
toPlot$counts
toPlot$counts[,JNPL3Plus]
toPlot$counts[,JNPL3Minus]
boxplot(toPlot$counts[,JNPL3Plus], use.cols = FALSE)
boxplot(toPlot$counts[,JNPL3Minus], use.cols = FALSE)
boxplot(toPlot$counts[,JNPL3Plus], use.cols = FALSE)
boxplot(toPlot$counts[,JNPL3Minus], use.cols = FALSE)
?data.frame
?melt
?melt.list
melt(toPlot)
data.frame(toPlot$counts, row.names = topTen)
toPlot$samples
data.frame(toPlot$counts, row.names = topTen, id=toPlot$samples$group)
data.frame(toPlot$counts, row.names = topTen)
melt(data.frame(toPlot$counts, row.names = topTen))
colnames(toPlot)
rownames(toPlot)
melt(data.frame(toPlot$counts, row.names = topTen), id.vars = rownames(toPlot))
data.frame(toPlot$counts, row.names = topTen)
?transpose
??transpose
t(data.frame(toPlot$counts, row.names = topTen))
melt(t(data.frame(toPlot$counts, row.names = topTen)))
melt(t(data.frame(toPlot$counts, row.names = topTen)))
toPlot2 <- melt(t(data.frame(toPlot$counts, row.names = topTen)))
toPlot2
class(toPlot2)
test <- data.frame(toPlot$counts, row.names = topTen)
test
test <- t(data.frame(toPlot$counts, row.names = topTen))
test
toPlot$samples
test
toPlot$samples
toPlot$samples$group
test$factor.col <- toPlot$samples$group
test
t(toPlot$samples$group)
toPlot$samples$group
unlist(toPlot$samples$group)
test$factor.col <- unlist(toPlot$samples$group)
test
test <- t(data.frame(toPlot$counts, row.names = topTen))
test
test$factor.col <- unlist(toPlot$samples$group)
test <- t(data.frame(toPlot$counts, row.names = topTen))
?rbind
cbind(test, toPlot$samples$group)
toPlot$samples$group
test
test <- cbind(test, toPlot$samples$group) #1 is JNPL3minus, 2 is JNPL3plus
test
melt(test)
boxplot(toPlot$counts[,JNPL3Plus], use.cols = FALSE)
boxplot(toPlot$counts[,JNPL3Minus], use.cols = FALSE)
?boxplot
boxplot(toPlot$samples$group, data=toPlot$counts, notch=TRUE,
col=(c("gold","darkgreen")),
main="Top 10 Differentially Expressed Genes", xlab="Gene ID")
boxplot(x~toPlot$samples$group, data=toPlot$counts, notch=TRUE,
col=(c("gold","darkgreen")),
main="Top 10 Differentially Expressed Genes", xlab="Gene ID")
boxplot(toPlot$counts~toPlot$samples$group, data=toPlot$counts, notch=TRUE,
col=(c("gold","darkgreen")),
main="Top 10 Differentially Expressed Genes", xlab="Gene ID")
toPlot$samples$group
toPlot$counts
boxplot(t(toPlot$counts)~toPlot$samples$group, data=t(toPlot$counts), notch=TRUE,
col=(c("gold","darkgreen")),
main="Top 10 Differentially Expressed Genes", xlab="Gene ID")
boxplot(toPlot$counts~t(toPlot$samples$group), data=toPlot$counts, notch=TRUE,
col=(c("gold","darkgreen")),
main="Top 10 Differentially Expressed Genes", xlab="Gene ID")
toPlot$counts
boxplot(t(toPlot$counts))
toPlot$samples$group
t(toPlot$counts)
t(toPlot$samples$group)
topTags
topTags(de_GLM, n=10)
topTags(de_glm, n = 10)
topTen <- rownames(topTags(de_glm, n = 10))
toPlot <- d[topTen] #10 rows, 24 columnst
class(toPlot)
str(toPlot)
cbind(toPlot$samples$group, t(toPlot$counts))
test <- cbind(toPlot$samples$group, t(toPlot$counts))
t(test)
melt(t(test))
test
t(test)
test  <- data.frame(toPlot$samples$group, t(toPlot$counts))
teest
test
melt(test)
toPlot2 <- melt(test)
toPlot2
ggplot(toPlot2, aes(factor(variable), value)) + geom_boxplot(aes(fill = Type))
ggplot(toPlot2, aes(factor(variable), value)) + geom_boxplot(aes(fill = toPlot.samples.group))
topTen
topTags(de_glm, n = 10)
de2tags <- rownames(d2)[as.logical(de2)]
plotSmear(de_glm, de.tags=de2tags)
abline(h = c(-2, 2), col = "blue")
-log(2)
de2tags
de2
head(de2)
?decideTestsDGE
ls
topTags(de_glm, n = 10)
top <- topTags(de.tgw, n=50)
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
geneNames <- getBM("external_gene_name", filters = "ensembl_gene_id", values = rownames(top), ensembl)
top <- cbind(top, geneNames)
top <- topTags(de_glm, n=50)
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
geneNames <- getBM("external_gene_name", filters = "ensembl_gene_id", values = rownames(top), ensembl)
top <- cbind(top, geneNames)
top
de_glm
class(d2)
d2$counts
rownames(top)
de2$counts[rownames(top), ]
de2$counts
d2$counts[rownames(top), ]
?mean
mewn(d2$counts[rownames(top), ])
mean(d2$counts[rownames(top), ])
rowMeans(d2$counts[rownames(top), ])
dim(rowMeans(d2$counts[rownames(top), ]))
lenght(rowMeans(d2$counts[rownames(top), ]))
length(rowMeans(d2$counts[rownames(top), ]))
dim(top)
means <- rowMeans(d2$counts[rownames(top), ])
top[1]
top[1,]
top <- cbind(top, means)
top[1,]
colnames(top)
colnames(top)[6]
colnames(d2)
colnames(d)
d[1,1]
d2[1,1]
colnames(top)[6] <- "Mean gene count"
apply(d2$counts,1,sd)
colnames(top)[last]
colnames(top)[end]
colnames(top)[]
colnames(top)
colnames(top)[7] <- "Gene count Std Dev"
sdevs <- apply(d2$counts,1,sd)
top <- cbind(top, stdevs)
colnames(top)[7] <- "Gene count Std Dev"
stdevs <- apply(d2$counts,1,sd)
top <- cbind(top, stdevs)
colnames(top)[7] <- "Gene count Std Dev"
stdevs
d2$counts
stdevs <- apply(d2$counts[rownames(top)], 1, sd)
stdevs <- apply(d2$counts[rownames(top), ], 1, sd)
top <- cbind(top, stdevs)
colnames(top)[7] <- "Gene count Std Dev"
top
colnames(top)[6] <- "Mean_count"
colnames(top)[7] <- "Count_Std_Dev"
top
colnames(top)[5] <- "Gene_Name"
top
kurtosis(d2$counts[rownames(top), ])
install.packages("PerformanceAnalytics")
library(performanceAnalytics) # for kertosis calculations
install.packages("PerformanceAnalytics")
install.packages("PerformanceAnalytics")
library(performanceAnalytics) # for kertosis calculations
library(PerformanceAnalytics) # for kertosis calculations
kertosis(d2$counts[rownames(top), ])
kurtosis(d2$counts[rownames(top), ])
kurtosises  <- kurtosis(d2$counts[rownames(top), ])
top <- cbind(top, kurtosises)
colnames(top)[7] <- "Count_Kurtosis"
top
top <- topTags(de_glm, n=50)
top
ensembl=useMart("ensembl", dataset="mmusculus_gene_ensembl")
geneNames <- getBM("external_gene_name", filters = "ensembl_gene_id", values = rownames(top), ensembl)
top <- cbind(top, geneNames)
colnames(top)[5] <- "Gene_Name"
top
means <- rowMeans(d2$counts[rownames(top), ])
top <- cbind(top, means)
colnames(top)[6] <- "Mean_count"
stdevs <- apply(d2$counts[rownames(top), ], 1, sd)
top <- cbind(top, stdevs)
colnames(top)[7] <- "Count_Std_Dev"
top
kurtosises  <- kurtosis(d2$counts[rownames(top), ])
cbind(top, kurtosises)
t(kurtosises)
cbind(top, t(kurtosises)
)
View(kurtosises)
rownames(top)
d2$counts[rownames(top), ]
?kurtosis
kurtosises  <- apply(d2$counts[rownames(top), ], 1, kurtosis)
kurtosises
cbind(top, kurtosises)
kurtosises  <- apply(d2$counts[rownames(top), ], 1, kurtosis)
top <- cbind(top, kurtosises)
colnames(top)[7] <- "Count_Kurtosis"
top
colnames(top)[7] <- "Count_Std_Dev"
colnames(top)[8] <- "Count_Kurtosis"
top
q()
q()
library(dplyr) # for subsetting data
library(R.utils) # for unzipping data
library(synapseClient) # to download data
library(edgeR) # for DE analysis
library(biomaRt) # for gene name lookups
library(ggplot2) # for better boxplots
library(reshape2) # for melt for ggplot
library(PerformanceAnalytics) # for kertosis calculations
## Get data and define groups
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
# get the transposed readcount file and covariates file from synapse
countFile <- synGet('syn3192634')
covariatesFile <- synGet('syn2875343') # the working dir copy
localCountFilePath <- getFileLocation(countFile)
if(!file.exists(sub('.gz', '', localCountFilePath))) {
gunzip(localCountFilePath)
}
localCountFilePath <- sub('.gz', '', localCountFilePath) #trim the .gz suffix
counts <- read.table(localCountFilePath, header = TRUE, stringsAsFactors = FALSE)
colnames(counts)[1] <- "LP_62_4"
# load covariates file to have handy
covariates <- read.table(getFileLocation(covariatesFile), header = TRUE, stringsAsFactors = FALSE)
# get JNPL3 subset of counts from counts file
JNPL3Counts <- dplyr::select(counts,
one_of(covariates[(covariates$Experiment == "MAPT_P301L"), ]$Mouse_ID))
# define groups
targets <- data.frame(Sample = covariates[(covariates$Experiment == "MAPT_P301L"), ]$Mouse_ID,
Genotype = covariates[(covariates$Experiment == "MAPT_P301L"), ]$Genotype,
Age = as.factor(covariates[(covariates$Experiment == "MAPT_P301L"), ]$Age_months))
group <- factor(paste(targets$Genotype, targets$Age, sep = "."))
JNPL3 <- (counts = JNPL3Counts, group = group)
JNPL3Counts
head(JNPL3Counts)
JNPL3 <- (counts = JNPL3Counts, group = group)
JNPL3 <- DGEList(counts = JNPL3Counts, group = group)
dim(JNPL3)
keep <- rowSums(cpm(JNPL3)>100) >= 2
d <- JNPL3[keep,]
dim(d)
#3133   24
d$samples$lib.size <- colSums(d$counts)
d <- calcNormFactors(d, method = "TMM")
plotMDS(d, method="bcv", col=as.numeric(d$samples$group))
legend("bottomleft", as.character(unique(d$samples$group)), col=1:3, pch=20)
design.mat <- model.matrix(~0 + targets$Genotype + targets$Genotype:targets$Age)
design.mat
colnames(design.mat)
targets
design.mat <- model.matrix(~0 + targets$Genotype + targets$Genotype:targets$Age)
colnames(design.mat)
factor(paste(targets$Age, targets$Genotype, sep=""))
testGroup <- factor(paste(targets$Age, targets$Genotype, sep=""))
testDesign.mat <- model.matrix(~0 + group)
testDesign.mat
design.mat
colnames(design.mat)
class(design.mat)
twoPlus <- c(rep(0, length(design.mat[1,])))
twoPlus
twoPlus <- c(rep(0, length(design.mat[,1])))
twoPlus
targets
twoPlus[16]
twoPlus[16] <- 1
twoPlus
twoPlus[17] <- 1
twoPlus[24] <- 1
q()
require(synapseClient)
synapseLogin()
#query the knowledge portal for all the mayo/ufl/isb data
df <- synQuery('select name,id from file where projectId==\'syn2580853\' and center==\'UFL-Mayo-ISB\'')
#grab all the synapse objects for all mayo/ufl/isb data, but don't download the data
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
#extract internal Synapse id from provenance of all files, and add it to the df table
mayoProvenance <- lapply(synapseEntity,function(x){return(synGetActivity(x))})
file.oldId <- sapply(mayoProvenance,function(x){return(x$used[[1]]$reference$targetId)})
df <- cbind(df,file.oldId)
df <- synQuery('select name,id from file where projectId==\'syn2580853\' and center==\'UFL-Mayo-ISB\'')
df
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
onWeb('syn3205812')
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
onWeb('syn3207163')
synapseEntity<-lapply(df$file.id,function(x){return(synGet(x,downloadFile = F))})
mayoProvenance <- lapply(synapseEntity,function(x){return(synGetActivity(x))})
file.oldId <- sapply(mayoProvenance,function(x){return(sapply(x$used,function(x){return(x$reference$targetId)}))})
names(file.oldId) <- df$file.id
df
file.oldId
sort(df$file.id)
q()
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("TODO")
source('http://depot.sagebase.org/CRAN.R')
pkgInstall("synapseClient")
install.packages(package, repos = c(sageRepo, "http://cran.r-project.org"),
)
install.packages(package, repos = c(sageRepo, "http://cran.r-project.org")
)
source('http://depot.sagebase.org/CRAN.R')
pkgInstall("synapseClient")
library(synapseClient)
library(R.utils)
library(edgeR)
#Login to Synapse using credentials saved in .synapseConfig file
synapseLogin()
codeFile <- ("TODO")
countFileSynapseIDs <- c('syn3483519', 'syn3483625')
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(transposedCounts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(normalizedCpm, newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(Counts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name)
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(normalizedCpm, newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
codeFile <- ("https://github.com/TODO")
countFileSynapseIDs <- c('syn3483519', 'syn3483625')
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(Counts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name) #legacy?
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(normalizedCpm, newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
countFileSynapseIDs <- c('syn3483625') #'syn3483519',
for (mergedCountFile in countFileSynapseIDs) {
message("Normalizing ", mergedCountFile)
# Download file from Synapse
originalCountFile <- synGet(mergedCountFile)
# unzip file and load for processing
localFilePath <- getFileLocation(originalCountFile)
if(!file.exists(substr(localFilePath, 1, nchar(localFilePath) - 3))) {
gunzip(localFilePath)
}
localFilePath <- sub('.gz', '', localFilePath) #trim the .gz suffix
Counts <- read.table(localFilePath, header = TRUE)
# make DGEList object
expr <- DGEList(Counts, group = rep(1, ncol(Counts)))
# calculate normalization factors
normFactors <- calcNormFactors(expr, method = ("TMM"))
# use normaliztion factors to calculate cpm -
# per https://www.biostars.org/p/84087/, that's calculated as
# count / (library size * normalization factor))
normalizedCpm <- cpm(normFactors)
# write the data to local dir
newFileName <- sub('_transposed.txt.gz', '', originalCountFile$properties$name) #legacy?
newFileName <- paste0(newFileName, "_normalized.txt", sep="")
write.table(normalizedCpm, newFileName, quote = FALSE, sep = "\t", row.names = TRUE)
# package it up, then create a Synapse object for the output file and upload with provenance
gzip(newFileName)
newFileName <- paste0(newFileName, ".gz", sep="")
parentId <- originalCountFile$properties$parentId
normalizedCountFile <- File(newFileName, parentId = parentId)
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
normalizedCountFile <- synStore(normalizedCountFile,
activityName="CPM (using TMM) from edgeR normalization",
used=list(list(name = "normalize_readcounts.R",
url = codeFile, wasExecuted = T),
list(entity=originalCountFile,
wasExecuted=F)))
}
setwd("~/Projects/UO1-AMP/working")
setwd("~/Projects/UO1-AMP/working/MBB_TCX_Work")
c("foo","bar")
?readxls
?readXls
??readxls
??xls
??read
?read.xls
q()
